{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "import torch.utils.data as data_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from visdom import Visdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"input/creditcard.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "x = df.iloc[:, :-1].values\n",
    "y = df.iloc[:,-1:].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, random_state = 21, shuffle = True, stratify = y)\n",
    "\n",
    "# Store Num Features\n",
    "n_features = x.shape[1]\n",
    "\n",
    "# Center Mean and Unit Variance\n",
    "x_train = preprocessing.scale(x_train, axis = 0)\n",
    "x_test = preprocessing.scale(x_test, axis = 0)\n",
    "\n",
    "# Mimic Real Data\n",
    "x_train = x_train[np.ravel(y_train == 0)]\n",
    "y_train = y_train[y_train == 0]\n",
    "\n",
    "# To Tensor\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_train = torch.from_numpy(y_train).double()\n",
    "y_test = torch.from_numpy(y_test).double()\n",
    "# if torch.cuda.is_available():\n",
    "#         x_train = x_train.cuda()\n",
    "#         x_test = x_test.cuda()\n",
    "#         y_train = y_train.cuda()\n",
    "#         y_test = y_test.cuda()\n",
    "\n",
    "# Creates Data Loader\n",
    "ds_train = data_utils.TensorDataset(x_train, y_train)\n",
    "data_loader = data_utils.DataLoader(ds_train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise Library\n",
    "num_noise_features = 50\n",
    "\n",
    "def uniform_noise(num_elements):\n",
    "    noise = torch.rand(num_elements, num_noise_features)\n",
    "    if torch.cuda.is_available():\n",
    "        return noise.cuda()\n",
    "    return noise\n",
    "\n",
    "def gaussian_noise(num_elements, mean = 0, stddev = 1):\n",
    "    noise = torch.empty(num_elements, num_noise_features).normal_(mean, stddev)\n",
    "    if torch.cuda.is_available():\n",
    "        return noise.cuda()\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References\n",
    "# https://github.com/soumith/ganhacks <-- real useful\n",
    "# https://github.com/diegoalejogm/gans\n",
    "# https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f\n",
    "\n",
    "# GAN NETWORKS\n",
    "\n",
    "# Regular Descriminator Network\n",
    "class DiscriminatorNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNetwork, self).__init__()\n",
    "#         self.hidden0 = nn.Sequential(\n",
    "#             nn.Linear(n_features, 256),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "        \n",
    "#         self.hidden1 = nn.Sequential(\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "        \n",
    "#         self.hidden2 = nn.Sequential(\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "        \n",
    "#         self.hidden3 = nn.Sequential(\n",
    "#             nn.Linear(64,32),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "        \n",
    "        self.hidden4 = nn.Sequential(\n",
    "            nn.Linear(n_features, 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x  = self.hidden0(x)\n",
    "#         x = self.hidden1(x)\n",
    "#         x = self.hidden2(x)\n",
    "#         x = self.hidden3(x)\n",
    "        x = self.hidden4(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "# Regular Generator Network    \n",
    "class GeneratorNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorNetwork, self).__init__()\n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(num_noise_features, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(128)\n",
    "        )\n",
    "        \n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "        \n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(32)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(32, n_features),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x  = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Creation Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Creation Wrappers\n",
    "\n",
    "def real_target(size):\n",
    "    target = Variable(torch.ones(size, 1))\n",
    "    if torch.cuda.is_available():\n",
    "        return target.cuda()\n",
    "    return target\n",
    "\n",
    "def fake_target(size):\n",
    "    target = Variable(torch.zeros(size, 1))\n",
    "    if torch.cuda.is_available():\n",
    "        return target.cuda()\n",
    "    return target\n",
    "\n",
    "def synthesize_data(gen_nn, batch_size, noise_function):\n",
    "    noise = noise_function(batch_size)\n",
    "    fake_data = gen_nn(noise)\n",
    "    return fake_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Functions\n",
    "def train_discriminator(discr_nn, discr_optimizer, gen_nn, real_data, noise_function):\n",
    "    discr_optimizer.zero_grad()\n",
    "    \n",
    "    # Makes Fake Data    \n",
    "    batch_size = real_data.size(0)\n",
    "    fake_data = synthesize_data(gen_nn, batch_size, noise_function)\n",
    "    \n",
    "    # Prediction On Fake Data     \n",
    "    fake_discr_pred = discr_nn(fake_data)\n",
    "    test = fake_target(batch_size)\n",
    "    fake_loss = loss(fake_discr_pred, fake_target(batch_size))\n",
    "    fake_loss.backward()\n",
    "    \n",
    "    # Prediction On Real Data     \n",
    "    real_discr_pred = discr_nn(real_data)\n",
    "    real_loss = loss(real_discr_pred, real_target(batch_size))\n",
    "    real_loss.backward()\n",
    "    \n",
    "    discr_optimizer.step()\n",
    "    \n",
    "    return fake_loss + real_loss\n",
    "\n",
    "def train_generator(gen_nn, gen_optimizer, discr_nn, real_data, noise_function):\n",
    "    gen_optimizer.zero_grad()\n",
    "    \n",
    "    # Makes Fake Data\n",
    "    batch_size = real_data.size(0)\n",
    "    fake_data = synthesize_data(gen_nn, batch_size, noise_function)\n",
    "    \n",
    "    # Prediction On Fake Data     \n",
    "    fake_discr_pred = discr_nn(fake_data)\n",
    "    gen_loss = loss(fake_discr_pred, real_target(batch_size)) # Maximizing as opposed to minimizeing\n",
    "    gen_loss.backward()\n",
    "    \n",
    "    gen_optimizer.step()\n",
    "    \n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density Estimation\n",
    "def GetDensityEstimation(data):\n",
    "    kde = KernelDensity(bandwidth=0.5, kernel=\"gaussian\")\n",
    "    return kde.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluations\n",
    "def EvaluateHellingerDistance(gen_nn, kde_function, real_data, noise_function):\n",
    "    fake_data = synthesize_data(gen_nn, real_data, noise_function)\n",
    "    \n",
    "#     fig, axs = plt.subplots(2)\n",
    "    \n",
    "    real_data_numpy = real_data.detach().cpu().numpy()#[:,0].reshape(-1,1)\n",
    "    real_kde = kde_function(real_data_numpy)\n",
    "    real_log_dens = real_kde.score_samples(real_data_numpy)\n",
    "    real_log_dens = np.exp(real_log_dens)\n",
    "    \n",
    "#     print(real_data_numpy.shape, real_log_dens.shape)\n",
    "#     axs[0].scatter(real_data_numpy[0,real_log_dens)\n",
    "    \n",
    "    fake_data_numpy = fake_data.detach().cpu().numpy()#[:,0].reshape(-1,1)\n",
    "    fake_kde = kde_function(fake_data_numpy)\n",
    "    fake_log_dens = fake_kde.score_samples(real_data_numpy)\n",
    "    fake_log_dens = np.exp(fake_log_dens)\n",
    "    print(np.sum(fake_log_dens))\n",
    "#     axs[1].scatter(real_data_numpy,fake_log_dens)\n",
    "    \n",
    "    return np.sqrt(np.sum((np.sqrt(real_log_dens) - np.sqrt(fake_log_dens)) ** 2)) / np.sqrt(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visdom Stuff\n",
    "class VisdomController():\n",
    "    def __init__(self):\n",
    "        self.vis = Visdom()\n",
    "        self.plots = {}\n",
    "        \n",
    "    def CreateLinePlot(self, data, title, xlabel, ylabel, win, key):\n",
    "            self.plots[win] = self.vis.line(data, opts=dict(\n",
    "                title=title,\n",
    "                xlabel=xlabel,\n",
    "                ylabel=ylabel,\n",
    "                win=win,\n",
    "                name=key\n",
    "            ))\n",
    "            \n",
    "    def CreateScatterPlot(self, data, title, xlabel, ylabel, plot_win):\n",
    "        self.plots[plot_win] = self.vis.scatter(data, opts=dict(\n",
    "                title=title,\n",
    "                xlabel=xlabel,\n",
    "                ylabel=ylabel,\n",
    "                win=plot_win\n",
    "            ))\n",
    "    \n",
    "    def UpdateLinePlot(self, x, y, win, key):\n",
    "        self.vis.line(np.array([y]), X=np.array([x]), win=self.plots[win], name=key, update=\"append\") \n",
    "        \n",
    "    def UpdateScatterPlot(self, data, win):\n",
    "        self.vis.scatter(data, win=self.plots[win], update=\"replace\")\n",
    "\n",
    "    def Plot_Loss(self, key, epoch, loss):\n",
    "        plot_win = \"loss_window\"\n",
    "        if plot_win not in self.plots:\n",
    "            self.CreateLinePlot(np.array([epoch, loss]), \"Loss Graph\", \"Epoch\", \"Loss\", plot_win, key)\n",
    "        else:\n",
    "            self.UpdateLinePlot(epoch, loss, plot_win, key)\n",
    "            \n",
    "    def Plot_Fake_Feature_Distribution_Comparison(self, f_idx_0, f_idx_1, gen_nn, batch_size, noise_function):\n",
    "        fake_data_0 = synthesize_data(gen_nn, batch_size, noise_function).detach().cpu().numpy()[:,f_idx_0]\n",
    "        fake_data_1 = synthesize_data(gen_nn, batch_size, noise_function).detach().cpu().numpy()[:,f_idx_1]\n",
    "        data = np.array([fake_data_0,fake_data_1]).T\n",
    "        \n",
    "        plot_win = str(f_idx_0 + f_idx_1) + \"_fake_comp_window\"\n",
    "        title = \"fake features : \" + str(f_idx_0) + \" vs \" + str(f_idx_1)\n",
    "        \n",
    "        if plot_win not in self.plots:\n",
    "            self.CreateScatterPlot(data, title, str(f_idx_0), str(f_idx_1), plot_win)\n",
    "        else:\n",
    "            self.UpdateScatterPlot(data, plot_win)\n",
    "            \n",
    "    def Plot_Real_Feature_Distribution_Comparison(self, f_idx_0, f_idx_1, real_data, num_samples):\n",
    "        rows = np.random.choice(np.arange(0,real_data.shape[0]), size=num_samples, replace=False)\n",
    "        data = real_data.detach().cpu().numpy()[:,[f_idx_0, f_idx_1]][rows,:]\n",
    "        print(data.shape)\n",
    "        \n",
    "        plot_win = str(f_idx_0 + f_idx_1) + \"_real_comp_window\"\n",
    "        title = \"real features : \" + str(f_idx_0) + \" vs \" + str(f_idx_1)\n",
    "        \n",
    "        if plot_win not in self.plots:\n",
    "            self.CreateScatterPlot(data, title, str(f_idx_0), str(f_idx_1), plot_win)\n",
    "        else:\n",
    "            self.UpdateScatterPlot(data, plot_win)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots --ARCHIVED--\n",
    "def PlotLoss(loss_history):\n",
    "    discr_loss_history = loss_history[0]\n",
    "    gen_loss_history = loss_history[1]\n",
    "    time_range = list(range(len(discr_loss_history)))\n",
    "    plt.plot(time_range, discr_loss_history, label = \"discr_loss\")\n",
    "    plt.plot(time_range, gen_loss_history, label = \"gen_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiated Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "\n",
    "# Models\n",
    "discr_nn = DiscriminatorNetwork()\n",
    "gen_nn = GeneratorNetwork()\n",
    "if torch.cuda.is_available():\n",
    "    discr_nn.cuda()\n",
    "    gen_nn.cuda()\n",
    "\n",
    "# Optimizers\n",
    "discr_optimizer = optim.SGD(discr_nn.parameters(), lr=0.0005)\n",
    "gen_optimizer = optim.Adam(gen_nn.parameters(), lr=0.0005)\n",
    "\n",
    "# Loss\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "# Visualizer\n",
    "vis = VisdomController()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, 900 / 2275\n",
      "discr_loss :  tensor(1.3859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "gen_loss :  tensor(0.6934, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Time Elapsed :  0.022939205169677734\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-4ae39a0a4d88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreal_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mdiscr_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_discriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscr_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscr_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mgen_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscr_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-aaf47faea4f5>\u001b[0m in \u001b[0;36mtrain_discriminator\u001b[1;34m(discr_nn, discr_optimizer, gen_nn, real_data, noise_function)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Prediction On Real Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mreal_discr_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscr_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mreal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_discr_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mreal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2483\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[1;32m-> 2484\u001b[1;33m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[0;32m   2485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test\n",
    "num_epochs = 100\n",
    "noise_function = gaussian_noise\n",
    "num_scatter_points = 80\n",
    "\n",
    "# One Off Graphs\n",
    "vis.plots = {}\n",
    "vis.Plot_Real_Feature_Distribution_Comparison(5, 6, x_train, num_scatter_points)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    discr_epoch_loss = 0\n",
    "    gen_epoch_loss = 0\n",
    "    for n_batch, (batch, _) in enumerate(data_loader):\n",
    "        real_batch = Variable(batch)\n",
    "        if torch.cuda.is_available():\n",
    "            real_batch = real_batch.cuda()\n",
    "        \n",
    "        t_start = millis = time.time()\n",
    "        batch_size = real_batch.size(0)\n",
    "        \n",
    "        discr_loss = train_discriminator(discr_nn, discr_optimizer, gen_nn, real_batch, noise_function)\n",
    "        gen_loss = train_generator(gen_nn, gen_optimizer, discr_nn, real_batch, noise_function)\n",
    "        \n",
    "        # Loss History\n",
    "        discr_epoch_loss += discr_loss\n",
    "        gen_epoch_loss += gen_loss\n",
    "        \n",
    "        if (n_batch % 100 == 0):\n",
    "            display.clear_output(True)\n",
    "            \n",
    "            # Basic Data            \n",
    "            print(\"Epoch {}, {} / {}\".format(epoch, n_batch, len(data_loader)))\n",
    "            print(\"discr_loss : \", discr_loss)\n",
    "            print(\"gen_loss : \", gen_loss) \n",
    "                        \n",
    "            # hellinger_dist = EvaluateHellingerDistance(gen_nn, GetDensityEstimation, real_batch, uniform_noise)\n",
    "            # print(\"hellinger_dist : \", (hellinger_dist))\n",
    "            \n",
    "            t_end = millis = time.time()\n",
    "            print(\"Time Elapsed : \", t_end - t_start)\n",
    "            \n",
    "    vis.Plot_Loss(\"Discr Loss\", epoch, discr_epoch_loss.item() / len(data_loader))\n",
    "    vis.Plot_Loss(\"Gen Loss\", epoch, gen_epoch_loss.item() / len(data_loader))   \n",
    "    vis.Plot_Fake_Feature_Distribution_Comparison(5, 6, gen_nn, num_scatter_points, noise_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
