{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "import torch.utils.data as data_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from visdom import Visdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"input/creditcard.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "x = df.iloc[:, :-1].values\n",
    "y = df.iloc[:,-1:].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, random_state = 21, shuffle = True, stratify = y)\n",
    "\n",
    "# Store Num Features\n",
    "n_features = x.shape[1]\n",
    "\n",
    "# Center Mean and Unit Variance\n",
    "x_train = preprocessing.scale(x_train, axis = 0)\n",
    "x_test = preprocessing.scale(x_test, axis = 0)\n",
    "\n",
    "# Mimic Real Data\n",
    "x_train = x_train[np.ravel(y_train == 0)]\n",
    "y_train = y_train[y_train == 0]\n",
    "\n",
    "# To Tensor\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_train = torch.from_numpy(y_train).double()\n",
    "y_test = torch.from_numpy(y_test).double()\n",
    "# if torch.cuda.is_available():\n",
    "#         x_train = x_train.cuda()\n",
    "#         x_test = x_test.cuda()\n",
    "#         y_train = y_train.cuda()\n",
    "#         y_test = y_test.cuda()\n",
    "\n",
    "# Creates Data Loader\n",
    "ds_train = data_utils.TensorDataset(x_train, y_train)\n",
    "data_loader = data_utils.DataLoader(ds_train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise Library\n",
    "num_noise_features = 50\n",
    "\n",
    "def uniform_noise(num_elements):\n",
    "    noise = torch.rand(num_elements, num_noise_features)\n",
    "    if torch.cuda.is_available():\n",
    "        return noise.cuda()\n",
    "    return noise\n",
    "\n",
    "def gaussian_noise(num_elements, mean = 0, stddev = 1):\n",
    "    noise = torch.empty(num_elements, num_noise_features).normal_(mean, stddev)\n",
    "    if torch.cuda.is_available():\n",
    "        return noise.cuda()\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References\n",
    "# https://github.com/soumith/ganhacks <-- real useful\n",
    "# https://github.com/diegoalejogm/gans\n",
    "# https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f\n",
    "\n",
    "# GAN NETWORKS\n",
    "\n",
    "# Regular Descriminator Network\n",
    "class DiscriminatorNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNetwork, self).__init__()\n",
    "#         self.hidden0 = nn.Sequential(\n",
    "#             nn.Linear(n_features, 256),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "        \n",
    "#         self.hidden1 = nn.Sequential(\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "        \n",
    "#         self.hidden2 = nn.Sequential(\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "        \n",
    "#         self.hidden3 = nn.Sequential(\n",
    "#             nn.Linear(64,32),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "        \n",
    "        self.hidden4 = nn.Sequential(\n",
    "            nn.Linear(n_features, 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x  = self.hidden0(x)\n",
    "#         x = self.hidden1(x)\n",
    "#         x = self.hidden2(x)\n",
    "#         x = self.hidden3(x)\n",
    "        x = self.hidden4(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "# Regular Generator Network    \n",
    "class GeneratorNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorNetwork, self).__init__()\n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(num_noise_features, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(128)\n",
    "        )\n",
    "        \n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "        \n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(32)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(32, n_features),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x  = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Creation Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Creation Wrappers\n",
    "\n",
    "def real_target(size):\n",
    "    target = Variable(torch.ones(size, 1))\n",
    "    if torch.cuda.is_available():\n",
    "        return target.cuda()\n",
    "    return target\n",
    "\n",
    "def fake_target(size):\n",
    "    target = Variable(torch.zeros(size, 1))\n",
    "    if torch.cuda.is_available():\n",
    "        return target.cuda()\n",
    "    return target\n",
    "\n",
    "def synthesize_data(gen_nn, real_data, noise_function):\n",
    "    batch_size = real_data.size()[0]\n",
    "    noise = noise_function(batch_size)\n",
    "    fake_data = gen_nn(noise)\n",
    "#     if torch.cuda.is_available():\n",
    "#         return fake_data.cuda()\n",
    "    return fake_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Functions\n",
    "def train_discriminator(discr_nn, discr_optimizer, gen_nn, real_data, noise_function):\n",
    "    discr_optimizer.zero_grad()\n",
    "    \n",
    "    # Makes Fake Data    \n",
    "    batch_size = real_data.size(0)\n",
    "    fake_data = synthesize_data(gen_nn, real_data, noise_function)\n",
    "    \n",
    "    # Prediction On Fake Data     \n",
    "    fake_discr_pred = discr_nn(fake_data)\n",
    "    test = fake_target(batch_size)\n",
    "    fake_loss = loss(fake_discr_pred, fake_target(batch_size))\n",
    "    fake_loss.backward()\n",
    "    \n",
    "    # Prediction On Real Data     \n",
    "    real_discr_pred = discr_nn(real_data)\n",
    "    real_loss = loss(real_discr_pred, real_target(batch_size))\n",
    "    real_loss.backward()\n",
    "    \n",
    "    discr_optimizer.step()\n",
    "    \n",
    "    return fake_loss + real_loss\n",
    "\n",
    "def train_generator(gen_nn, gen_optimizer, discr_nn, real_data, noise_function):\n",
    "    gen_optimizer.zero_grad()\n",
    "    \n",
    "    # Makes Fake Data\n",
    "    batch_size = real_data.size(0)\n",
    "    fake_data = synthesize_data(gen_nn, real_data, noise_function)\n",
    "    \n",
    "    # Prediction On Fake Data     \n",
    "    fake_discr_pred = discr_nn(fake_data)\n",
    "    gen_loss = loss(fake_discr_pred, real_target(batch_size)) # Maximizing as opposed to minimizeing\n",
    "    gen_loss.backward()\n",
    "    \n",
    "    gen_optimizer.step()\n",
    "    \n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density Estimation\n",
    "def GetDensityEstimation(data):\n",
    "    kde = KernelDensity(bandwidth=0.5, kernel=\"gaussian\")\n",
    "    return kde.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluations\n",
    "def EvaluateHellingerDistance(gen_nn, kde_function, real_data, noise_function):\n",
    "    fake_data = synthesize_data(gen_nn, real_data, noise_function)\n",
    "    \n",
    "#     fig, axs = plt.subplots(2)\n",
    "    \n",
    "    real_data_numpy = real_data.detach().cpu().numpy()#[:,0].reshape(-1,1)\n",
    "    real_kde = kde_function(real_data_numpy)\n",
    "    real_log_dens = real_kde.score_samples(real_data_numpy)\n",
    "    real_log_dens = np.exp(real_log_dens)\n",
    "    \n",
    "#     print(real_data_numpy.shape, real_log_dens.shape)\n",
    "#     axs[0].scatter(real_data_numpy[0,real_log_dens)\n",
    "    \n",
    "    fake_data_numpy = fake_data.detach().cpu().numpy()#[:,0].reshape(-1,1)\n",
    "    fake_kde = kde_function(fake_data_numpy)\n",
    "    fake_log_dens = fake_kde.score_samples(real_data_numpy)\n",
    "    fake_log_dens = np.exp(fake_log_dens)\n",
    "    print(np.sum(fake_log_dens))\n",
    "#     axs[1].scatter(real_data_numpy,fake_log_dens)\n",
    "    \n",
    "    return np.sqrt(np.sum((np.sqrt(real_log_dens) - np.sqrt(fake_log_dens)) ** 2)) / np.sqrt(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visdom Stuff\n",
    "class VisdomController():\n",
    "    def __init__(self):\n",
    "        self.vis = Visdom()\n",
    "        self.plots = {}\n",
    "        \n",
    "    def CreatePlot(self, data, title, xlabel, ylabel, win, key):\n",
    "            self.plots[win] = self.vis.line(data, opts=dict(\n",
    "                title=title,\n",
    "                xlabel=xlabel,\n",
    "                ylabel=ylabel,\n",
    "                win=win,\n",
    "                name=key\n",
    "            ))\n",
    "    \n",
    "    def UpdatePlot(self, x, y, win, key):\n",
    "        self.vis.line(np.array([y]), X=np.array([x]), win=self.plots[win], name=key, update=\"append\") \n",
    "\n",
    "    def Plot_Loss(self, key, epoch, loss):\n",
    "        plot_win = \"loss_window\"\n",
    "        if plot_win not in self.plots:\n",
    "            self.CreatePlot(np.array([epoch, loss]), \"Loss Graph\", \"Epoch\", \"Loss\", plot_win, key)\n",
    "        else:\n",
    "            self.UpdatePlot(epoch, loss, plot_win, key)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots --ARCHIVED--\n",
    "def PlotLoss(loss_history):\n",
    "    discr_loss_history = loss_history[0]\n",
    "    gen_loss_history = loss_history[1]\n",
    "    time_range = list(range(len(discr_loss_history)))\n",
    "    plt.plot(time_range, discr_loss_history, label = \"discr_loss\")\n",
    "    plt.plot(time_range, gen_loss_history, label = \"gen_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiated Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "\n",
    "# Models\n",
    "discr_nn = DiscriminatorNetwork()\n",
    "gen_nn = GeneratorNetwork()\n",
    "if torch.cuda.is_available():\n",
    "    discr_nn.cuda()\n",
    "    gen_nn.cuda()\n",
    "\n",
    "# Optimizers\n",
    "discr_optimizer = optim.SGD(discr_nn.parameters(), lr=0.0005)\n",
    "gen_optimizer = optim.Adam(gen_nn.parameters(), lr=0.0005)\n",
    "\n",
    "# Loss\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "# Visualizer\n",
    "vis = VisdomController()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99, 2200 / 2275\n",
      "discr_loss :  tensor(1.3864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "gen_loss :  tensor(0.6933, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Time Elapsed :  0.012966156005859375\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    discr_epoch_loss = 0\n",
    "    gen_epoch_loss = 0\n",
    "    for n_batch, (batch, _) in enumerate(data_loader):\n",
    "        real_batch = Variable(batch)\n",
    "        if torch.cuda.is_available():\n",
    "            real_batch = real_batch.cuda()\n",
    "        \n",
    "        t_start = millis = time.time()\n",
    "        batch_size = real_batch.size(0)\n",
    "        \n",
    "        discr_loss = train_discriminator(discr_nn, discr_optimizer, gen_nn, real_batch, gaussian_noise)\n",
    "        gen_loss = train_generator(gen_nn, gen_optimizer, discr_nn, real_batch, gaussian_noise)\n",
    "        \n",
    "        # Loss History\n",
    "        discr_epoch_loss += discr_loss\n",
    "        gen_epoch_loss += gen_loss\n",
    "        \n",
    "        if (n_batch % 100 == 0):\n",
    "            display.clear_output(True)\n",
    "            \n",
    "            # Basic Data            \n",
    "            print(\"Epoch {}, {} / {}\".format(epoch, n_batch, len(data_loader)))\n",
    "            print(\"discr_loss : \", discr_loss)\n",
    "            print(\"gen_loss : \", gen_loss) \n",
    "                        \n",
    "            # hellinger_dist = EvaluateHellingerDistance(gen_nn, GetDensityEstimation, real_batch, uniform_noise)\n",
    "            # print(\"hellinger_dist : \", (hellinger_dist))\n",
    "            \n",
    "            t_end = millis = time.time()\n",
    "            print(\"Time Elapsed : \", t_end - t_start)\n",
    "            \n",
    "    vis.Plot_Loss(\"Discr Loss\", epoch, discr_epoch_loss.item() / len(data_loader))\n",
    "    vis.Plot_Loss(\"Gen Loss\", epoch, gen_epoch_loss.item() / len(data_loader))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
