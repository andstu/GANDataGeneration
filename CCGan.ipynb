{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "import torch.utils.data as data_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from visdom import Visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'window_3900402f0a4404'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visdom\n",
    "vis = Visdom()\n",
    "\n",
    "vis.line(np.zeros(2), opts=dict(\n",
    "    title=\"LossOverEpochs\",\n",
    "    xlabel=\"epoch\",\n",
    "    y_label=\"loss\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"input/creditcard.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "x = df.iloc[:, :-1].values\n",
    "y = df.iloc[:,-1:].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, random_state = 21, shuffle = True, stratify = y)\n",
    "\n",
    "# Store Num Features\n",
    "n_features = x.shape[1]\n",
    "\n",
    "# Center Mean and Unit Variance\n",
    "x_train = preprocessing.scale(x_train, axis = 0)\n",
    "x_test = preprocessing.scale(x_test, axis = 0)\n",
    "\n",
    "# Mimic Real Data\n",
    "x_train = x_train[np.ravel(y_train == 0)]\n",
    "y_train = y_train[y_train == 0]\n",
    "\n",
    "# To Tensor\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_train = torch.from_numpy(y_train).double()\n",
    "y_test = torch.from_numpy(y_test).double()\n",
    "# if torch.cuda.is_available():\n",
    "#         x_train = x_train.cuda()\n",
    "#         x_test = x_test.cuda()\n",
    "#         y_train = y_train.cuda()\n",
    "#         y_test = y_test.cuda()\n",
    "\n",
    "# Creates Data Loader\n",
    "ds_train = data_utils.TensorDataset(x_train, y_train)\n",
    "data_loader = data_utils.DataLoader(ds_train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise Library\n",
    "num_noise_features = 100\n",
    "\n",
    "def uniform_noise(num_elements):\n",
    "    noise = torch.rand(num_elements, num_noise_features)\n",
    "    if torch.cuda.is_available():\n",
    "        return noise.cuda()\n",
    "    return noise\n",
    "\n",
    "def gaussian_noise(num_elements, mean = 0, stddev = 1):\n",
    "    noise = torch.empty(num_elements, num_noise_features).normal_(mean, stddev)\n",
    "    if torch.cuda.is_available():\n",
    "        return noise.cuda()\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References\n",
    "# https://github.com/soumith/ganhacks <-- real useful\n",
    "# https://github.com/diegoalejogm/gans\n",
    "# https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f\n",
    "\n",
    "# GAN NETWORKS\n",
    "\n",
    "# Regular Descriminator Network\n",
    "class DiscriminatorNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNetwork, self).__init__()\n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.hidden3 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.hidden4 = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x  = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.hidden4(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "# Regular Generator Network    \n",
    "class GeneratorNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorNetwork, self).__init__()\n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(num_noise_features, 128),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(32, n_features),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x  = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Creation Wrappers\n",
    "\n",
    "def real_target(size):\n",
    "    target = Variable(torch.ones(size, 1))\n",
    "    if torch.cuda.is_available():\n",
    "        return target.cuda()\n",
    "    return target\n",
    "\n",
    "def fake_target(size):\n",
    "    target = Variable(torch.zeros(size, 1))\n",
    "    if torch.cuda.is_available():\n",
    "        return target.cuda()\n",
    "    return target\n",
    "\n",
    "def synthesize_data(gen_nn, real_data, noise_function):\n",
    "    batch_size = real_data.size()[0]\n",
    "    noise = noise_function(batch_size)\n",
    "    fake_data = gen_nn(noise)\n",
    "#     if torch.cuda.is_available():\n",
    "#         return fake_data.cuda()\n",
    "    return fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Functions\n",
    "def train_discriminator(discr_nn, discr_optimizer, gen_nn, real_data, noise_function):\n",
    "    discr_optimizer.zero_grad()\n",
    "    \n",
    "    # Makes Fake Data    \n",
    "    batch_size = real_data.size(0)\n",
    "    fake_data = synthesize_data(gen_nn, real_data, noise_function)\n",
    "    \n",
    "    # Prediction On Fake Data     \n",
    "    fake_discr_pred = discr_nn(fake_data)\n",
    "    test = fake_target(batch_size)\n",
    "    fake_loss = loss(fake_discr_pred, fake_target(batch_size))\n",
    "    fake_loss.backward()\n",
    "    \n",
    "    # Prediction On Real Data     \n",
    "    real_discr_pred = discr_nn(real_data)\n",
    "    real_loss = loss(real_discr_pred, real_target(batch_size))\n",
    "    real_loss.backward()\n",
    "    \n",
    "    discr_optimizer.step()\n",
    "    \n",
    "    return fake_loss + real_loss\n",
    "\n",
    "def train_generator(gen_nn, gen_optimizer, discr_nn, real_data, noise_function):\n",
    "    gen_optimizer.zero_grad()\n",
    "    \n",
    "    # Makes Fake Data\n",
    "    batch_size = real_data.size(0)\n",
    "    fake_data = synthesize_data(gen_nn, real_data, noise_function)\n",
    "    \n",
    "    # Prediction On Fake Data     \n",
    "    fake_discr_pred = discr_nn(fake_data)\n",
    "    gen_loss = loss(fake_discr_pred, real_target(batch_size)) # Maximizing as opposed to minimizeing\n",
    "    gen_loss.backward()\n",
    "    \n",
    "    gen_optimizer.step()\n",
    "    \n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density Estimation\n",
    "def GetDensityEstimation(data):\n",
    "    kde = KernelDensity(bandwidth=0.5, kernel=\"gaussian\")\n",
    "    return kde.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluations\n",
    "def EvaluateHellingerDistance(gen_nn, kde_function, real_data, noise_function):\n",
    "    fake_data = synthesize_data(gen_nn, real_data, noise_function)\n",
    "    \n",
    "#     fig, axs = plt.subplots(2)\n",
    "    \n",
    "    real_data_numpy = real_data.detach().cpu().numpy()#[:,0].reshape(-1,1)\n",
    "    real_kde = kde_function(real_data_numpy)\n",
    "    real_log_dens = real_kde.score_samples(real_data_numpy)\n",
    "    real_log_dens = np.exp(real_log_dens)\n",
    "    \n",
    "#     print(real_data_numpy.shape, real_log_dens.shape)\n",
    "#     axs[0].scatter(real_data_numpy[0,real_log_dens)\n",
    "    \n",
    "    fake_data_numpy = fake_data.detach().cpu().numpy()#[:,0].reshape(-1,1)\n",
    "    fake_kde = kde_function(fake_data_numpy)\n",
    "    fake_log_dens = fake_kde.score_samples(real_data_numpy)\n",
    "    fake_log_dens = np.exp(fake_log_dens)\n",
    "    print(np.sum(fake_log_dens))\n",
    "#     axs[1].scatter(real_data_numpy,fake_log_dens)\n",
    "    \n",
    "    return np.sqrt(np.sum((np.sqrt(real_log_dens) - np.sqrt(fake_log_dens)) ** 2)) / np.sqrt(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots\n",
    "def PlotLoss(loss_history):\n",
    "    discr_loss_history = loss_history[0]\n",
    "    gen_loss_history = loss_history[1]\n",
    "    time_range = list(range(len(discr_loss_history)))\n",
    "    plt.plot(time_range, discr_loss_history, label = \"discr_loss\")\n",
    "    plt.plot(time_range, gen_loss_history, label = \"gen_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "# Models\n",
    "discr_nn = DiscriminatorNetwork()\n",
    "gen_nn = GeneratorNetwork()\n",
    "if torch.cuda.is_available():\n",
    "    discr_nn.cuda()\n",
    "    gen_nn.cuda()\n",
    "\n",
    "# Optimizers\n",
    "discr_optimizer = optim.SGD(discr_nn.parameters(), lr=0.0003)\n",
    "gen_optimizer = optim.Adam(gen_nn.parameters(), lr=0.0003)\n",
    "\n",
    "# Loss\n",
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 500 / 2275\n",
      "discr_loss :  tensor(1.3903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "gen_loss :  tensor(0.6719, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed :  0.118682861328125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-75cb8df8b99d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreal_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mdiscr_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_discriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscr_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscr_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform_noise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mgen_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscr_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform_noise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-4265f31128fe>\u001b[0m in \u001b[0;36mtrain_discriminator\u001b[1;34m(discr_nn, discr_optimizer, gen_nn, real_data, noise_function)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mfake_discr_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscr_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfake_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mfake_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_discr_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mfake_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2483\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[1;32m-> 2484\u001b[1;33m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[0;32m   2485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test\n",
    "num_epochs = 100\n",
    "loss_history = [[],[]]\n",
    "for epoch in range(num_epochs):\n",
    "    loss_history[0].append(0)\n",
    "    loss_history[1].append(0)\n",
    "    \n",
    "    for n_batch, (batch, _) in enumerate(data_loader):\n",
    "#         print(batch.shape)\n",
    "        real_batch = Variable(batch)\n",
    "        if torch.cuda.is_available():\n",
    "            real_batch = real_batch.to(\"cuda\")\n",
    "        \n",
    "        t_start = millis = time.time()\n",
    "        batch_size = real_batch.size(0)\n",
    "        \n",
    "        discr_loss = train_discriminator(discr_nn, discr_optimizer, gen_nn, real_batch, uniform_noise)\n",
    "        gen_loss = train_generator(gen_nn, gen_optimizer, discr_nn, real_batch, uniform_noise)\n",
    "        \n",
    "        # Loss History\n",
    "        loss_history[0][epoch] += discr_loss / len(data_loader)\n",
    "        loss_history[1][epoch] += gen_loss / len(data_loader)\n",
    "        \n",
    "        if (n_batch % 100 == 0):\n",
    "            display.clear_output(True)\n",
    "            \n",
    "            print(\"Epoch {}, {} / {}\".format(epoch, n_batch, len(data_loader)))\n",
    "            print(\"discr_loss : \", discr_loss)\n",
    "            print(\"gen_loss : \", gen_loss)            \n",
    "#             hellinger_dist = EvaluateHellingerDistance(gen_nn, GetDensityEstimation, real_batch, uniform_noise)\n",
    "#             print(\"hellinger_dist : \", (hellinger_dist))\n",
    "\n",
    "            PlotLoss(loss_history)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "            t_end = millis = time.time()\n",
    "            print(\"Time Elapsed : \", t_end - t_start)\n",
    "\n",
    "#     loss_history[0][epoch] /= len(data_loader)\n",
    "#     loss_history[1][epoch] /= len(data_loader)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
