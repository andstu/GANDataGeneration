{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import average_precision_score, recall_score, f1_score\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "import torch.utils.data as data_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from visdom import Visdom\n",
    "\n",
    "from lib.VisdomWrapper import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "file_path = \"input/creditcard.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "x = df.iloc[:, :-1].values\n",
    "y = df.iloc[:,-1:].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, random_state = 21, shuffle = True, stratify = y)\n",
    "\n",
    "# Store Num Features\n",
    "n_features = x.shape[1]\n",
    "\n",
    "# Center Mean and Unit Variance\n",
    "x_train = preprocessing.scale(x_train, axis = 0)\n",
    "x_test = preprocessing.scale(x_test, axis = 0)\n",
    "\n",
    "# To Tensor\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "x_test = Variable(torch.from_numpy(x_test).float())\n",
    "y_train = torch.from_numpy(y_train).double()\n",
    "y_test = torch.from_numpy(y_test).double()\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)\n",
    "dtype = torch.float32\n",
    "\n",
    "# Creates Data Loader\n",
    "ds_train = data_utils.TensorDataset(x_train, y_train)\n",
    "data_loader = data_utils.DataLoader(ds_train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "vis = VisdomController()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architechure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FraudClassifier, self).__init__()\n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(256)\n",
    "        )\n",
    "        \n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.hidden3 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.hidden4 = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x  = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.hidden4(x)\n",
    "        x = self.out(x)\n",
    "        return x  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "BCE = nn.BCELoss()\n",
    "\n",
    "def train_classifier_vanilla(network, optimizer, data):\n",
    "    network = network.to(device=device)\n",
    "    n = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for n_batch, (x, y) in enumerate(data):\n",
    "            n += 1\n",
    "            network.train()\n",
    "            x = x.to(device=device, dtype = dtype)\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            t_start = millis = time.time()\n",
    "            \n",
    "            scores = network(x)\n",
    "            loss = BCE(scores, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Loss History\n",
    "            epoch_loss += loss\n",
    "            \n",
    "            if (n_batch % 100 == 0):\n",
    "                display.clear_output(True)\n",
    "\n",
    "                # Basic Data            \n",
    "                print(\"Epoch {}, {} / {}\".format(epoch, n_batch, len(data)))\n",
    "                print(\"loss : \", loss)\n",
    "            \n",
    "                t_end = millis = time.time()\n",
    "                print(\"Time Elapsed : \", t_end - t_start)\n",
    "                print(n)\n",
    "                vis.PlotLoss(\"Vanilla Loss\", n , loss.item())\n",
    "            \n",
    "        #vis.Plot_Loss(\"Vanilla Loss\", epoch, epoch_loss.item() / len(data))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, 2200 / 2279\n",
      "loss :  tensor(0.0012, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Time Elapsed :  0.00400090217590332\n",
      "11317\n"
     ]
    }
   ],
   "source": [
    "vanillaNN = FraudClassifier()\n",
    "vanillaOptim = optim.Adam(vanillaNN.parameters(), lr = 1e-5)\n",
    "\n",
    "train_classifier_vanilla(vanillaNN, vanillaOptim, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanillaNN.cuda()\n",
    "x_test = x_test.cuda()\n",
    "y_scores = vanillaNN(x_test)\n",
    "y_pred = np.round(y_scores.detach().cpu().numpy())\n",
    "average_precision = average_precision_score(y_test.cpu().numpy(), y_pred)\n",
    "print(\"Prec:\\t\", average_precision)\n",
    "print(\"Recall:\\t\", recall_score(y_test.cpu().numpy(), y_pred))\n",
    "print(\"F1:\\t\", f1_score(y_test.cpu().numpy(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
