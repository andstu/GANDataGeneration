{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from visdom import Visdom\n",
    "\n",
    "from lib.VisdomWrapper import *\n",
    "from lib.DataManager import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "num_epochs = 30\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "vis = VisdomController()\n",
    "\n",
    "mnist = dset.MNIST('input', train=True, download=True, transform=T.ToTensor())\n",
    "balanced_train = DataLoader(mnist, batch_size =batch_size, shuffle=True)\n",
    "\n",
    "mnist_low_zero = get_unbalanced_mnist([.05, .15, .1, .1, .1, .1, .1, .1, .1, .1], batch_size=batch_size)\n",
    "\n",
    "mnist_test=dset.MNIST('input', train=False, download=True, transform=T.ToTensor())\n",
    "balanced_test = DataLoader(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=5, stride=1),\n",
    "        nn.LeakyReLU(0.01),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=5, stride=1),\n",
    "        nn.LeakyReLU(0.01),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(4*4*64, 4*4*64, bias=True),\n",
    "        nn.LeakyReLU(0.01),\n",
    "        nn.Linear(4*4*64, 10, bias=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(classifier, optimizer, data, key=\"Loss\"):\n",
    "    for epoch in range(num_epochs):\n",
    "        for n_batch, (x, y) in enumerate(data):\n",
    "            if len(x) != batch_size:\n",
    "                continue\n",
    "            optimizer.zero_grad\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            scores = classifier(x)\n",
    "            out = loss(scores, y)\n",
    "            out.backward()\n",
    "            optimizer.step()\n",
    "        display.clear_output(True)\n",
    "        print(\"Epoch {}, {} / {}\".format(epoch, n_batch, len(data)))\n",
    "        print(\"Loss: \", out.item())\n",
    "        vis.loss_axis = epoch\n",
    "        vis.PlotLoss(key, out.item())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    print('Accuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 117 / 118\n",
      "Loss:  0.06898085027933121\n"
     ]
    }
   ],
   "source": [
    "balanced_net = build_classifier().cuda()\n",
    "balanced_net.train()\n",
    "train_classifier(balanced_net, get_optimizer(balanced_net), balanced_train, key=\"Balanced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 117 / 118\n",
      "Loss:  0.04684881865978241\n"
     ]
    }
   ],
   "source": [
    "low_zero_net = build_classifier().cuda()\n",
    "low_zero_net.train()\n",
    "train_classifier(low_zero_net, get_optimizer(low_zero_net), mnist_low_zero, key=\"Low Zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9675/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "balanced_net.eval()\n",
    "test(balanced_net, device, balanced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8854/10000 (89%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "low_zero_net.eval()\n",
    "test(low_zero_net, device, balanced_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
