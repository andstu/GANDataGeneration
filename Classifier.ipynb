{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from visdom import Visdom\n",
    "\n",
    "from lib.VisdomWrapper import *\n",
    "from lib.DataManager import *\n",
    "from lib.GANs import *\n",
    "from lib.DataCreationWrapper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Options\n",
    "bal_raw = False\n",
    "bal_syn = False\n",
    "bal_aug = False\n",
    "zer_raw = False\n",
    "zer_syn = False\n",
    "zer_aug = False\n",
    "nin_raw = False\n",
    "nin_syn = False\n",
    "nin_aug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "batch_size = 512\n",
    "num_epochs = 30\n",
    "img_width = 28 #hardcoded\n",
    "n_features = img_width**2\n",
    "n_noise_features = 100\n",
    "n_classes = 10\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "vis = VisdomController()\n",
    "\n",
    "mnist = dset.MNIST('input', train=True, download=True, transform=T.ToTensor())\n",
    "mnist_low_zero = get_unbalanced_mnist([.01, .1, .1, .1, .1, .1, .1, .1, .1, .1], batch_size=batch_size)\n",
    "mnist_high_nine = get_unbalanced_mnist([.1, .1, .1, .1, .1, .1, .1, .1, .1, 1], batch_size=batch_size)\n",
    "\n",
    "mnist_test=dset.MNIST('input', train=False, download=True, transform=T.ToTensor())\n",
    "balanced_test = DataLoader(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_balance(labels):\n",
    "    cnts = torch.bincount(labels)\n",
    "    max = torch.max(cnts)\n",
    "    return (max * torch.ones(len(cnts)) - cnts).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "\n",
    "with torch.no_grad():\n",
    "    if bal_raw or bal_aug:\n",
    "        bal_train = DataLoader(mnist, batch_size =1000)\n",
    "        X, Y = data_loader_to_tensor(bal_train)\n",
    "        bal_train = DataLoader(TensorDataset(X, Y), batch_size=batch_size, shuffle=True)\n",
    "        X, Y = None, None\n",
    "    \n",
    "    if bal_syn or bal_aug:\n",
    "        bal_gen = GeneratorNetwork(n_noise_features, n_features, n_classes)\n",
    "        bal_gen.load_state_dict(torch.load(\"models\\gen_nn_bal\"))\n",
    "        bal_gen.eval()\n",
    "        if bal_syn:\n",
    "            synth_data, synth_labels = synthesize_data_of_each_label(bal_gen, gaussian_noise, 6000 * np.ones(10))\n",
    "            synth_bal_data_loader = DataLoader(TensorDataset(synth_data.view(len(synth_labels), 1, 28, 28), synth_labels), batch_size=batch_size, shuffle=True)\n",
    "            synth_data, synth_labels = None, None\n",
    "        if bal_aug:\n",
    "            synth_data, synth_labels = synthesize_data_of_each_label(bal_gen, gaussian_noise, calc_balance(bal_train.dataset.tensors[1]) * np.ones(10))\n",
    "            synth_data = torch.cat(synth_data, bal_train.dataset.tensors[0])\n",
    "            synth_labels = torch.cat(synth_labels, bal_train.dataset.tensors[1])\n",
    "            aug_bal_data_loader = DataLoader(TensorDataset(synth_data.view(len(synth_labels), 1, 28, 28), synth_labels), batch_size=batch_size, shuffle=True)\n",
    "            synth_data, synth_labels = None, None\n",
    "\n",
    "    if zer_syn or zer_aug:\n",
    "        zer_gen = GeneratorNetwork(n_noise_features, n_features, n_classes)\n",
    "        zer_gen.load_state_dict(torch.load(\"models\\gen_nn_low_zero\"))\n",
    "        zer_gen.eval()\n",
    "        if zer_syn:\n",
    "            synth_data, synth_labels = synthesize_data_of_each_label(zer_gen, gaussian_noise, 6000 * np.ones(10))\n",
    "            syn_low_zero_data_loader = DataLoader(TensorDataset(synth_data.view(len(synth_labels), 1, 28, 28), synth_labels), batch_size=batch_size, shuffle=True)\n",
    "            synth_data, synth_labels = None, None\n",
    "\n",
    "    if nin_syn or nin_aug:\n",
    "        nin_gen = GeneratorNetwork(n_noise_features, n_features, n_classes)\n",
    "        nin_gen.load_state_dict(torch.load(\"models\\gen_nn_high_nine\"))\n",
    "        nin_gen.eval()\n",
    "        if zer_syn:\n",
    "            synth_data, synth_labels = synthesize_data_of_each_label(zer_gen, gaussian_noise, 6000 * np.ones(10))\n",
    "            syn_nin_data_loader = DataLoader(TensorDataset(synth_data.view(len(synth_labels), 1, 28, 28), synth_labels), batch_size=batch_size, shuffle=True)\n",
    "            synth_data, synth_labels = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frequency(data_loader, title):\n",
    "    x = np.arange(10)\n",
    "    cnts = torch.zeros(10)\n",
    "    for _, y in data_loader:\n",
    "        cnts += torch.bincount(y.cpu())\n",
    "    vis.CreateStaticBarPlot(cnts, x, title, \"Class\", \"Count\", \"FreqPlot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=5, stride=1),\n",
    "        nn.LeakyReLU(0.01),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=5, stride=1),\n",
    "        nn.LeakyReLU(0.01),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(4*4*64, 4*4*64, bias=True),\n",
    "        nn.LeakyReLU(0.01),\n",
    "        nn.Linear(4*4*64, 10, bias=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(classifier, optimizer, data, key=\"Loss\"):\n",
    "    for epoch in range(num_epochs):\n",
    "        for n_batch, (x, y) in enumerate(data):\n",
    "            if len(x) != batch_size:\n",
    "                continue\n",
    "            optimizer.zero_grad()\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            scores = classifier(x)\n",
    "            out = loss(scores, y)\n",
    "            out.backward()\n",
    "            optimizer.step()\n",
    "        display.clear_output(True)\n",
    "        print(\"Epoch {}, {} / {}\".format(epoch, n_batch, len(data)))\n",
    "        print(\"Loss: \", out.item())\n",
    "        vis.loss_axis = epoch\n",
    "        vis.PlotLoss(key, out.item())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    print('Accuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bal_raw\n",
    "    balanced_net = build_classifier().cuda()\n",
    "    balanced_net.train()\n",
    "    train_classifier(balanced_net, get_optimizer(balanced_net), bal_train, key=\"Balanced Raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bal_aug:\n",
    "    balanced_aug_net = build_classifier().cuda()\n",
    "    balanced_aug_net.train()\n",
    "    train_classifier(balanced_aug_net, get_optimizer(balanced_aug_net), aug_bal_data_loader, key=\"Balanced Aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bal_syn:\n",
    "    balanced_syn_net = build_classifier().cuda()\n",
    "    balanced_syn_net.train()\n",
    "    train_classifier(balanced_syn_net, get_optimizer(balanced_syn_net), syn_bal_data_loader, key=\"Balanced Synth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zer_raw:\n",
    "    low_zero_net = build_classifier().cuda()\n",
    "    low_zero_net.train()\n",
    "    train_classifier(low_zero_net, get_optimizer(low_zero_net), mnist_low_zero, key=\"Low Zero Aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nin_raw:\n",
    "    high_nine_net = build_classifier().cuda()\n",
    "    high_nine_net.train()\n",
    "    train_classifier(high_nine_net, get_optimizer(high_nine_net), mnist_high_nine, key=\"High Nine Raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bal_raw\n",
    "    device = torch.device(\"cuda\")\n",
    "    balanced_net.eval()\n",
    "    test(balanced_net, device, balanced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bal_aug:\n",
    "    device = torch.device(\"cuda\")\n",
    "    balanced_aug_net.eval()\n",
    "    test(balanced_aug_net, device, balanced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zer_raw:\n",
    "    device = torch.device(\"cuda\")\n",
    "    low_zero_net.eval()\n",
    "    test(low_zero_net, device, balanced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nin_raw:\n",
    "    device = torch.device(\"cuda\")\n",
    "    high_nine_net.eval()\n",
    "    test(high_nine_net, device, balanced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zer_syn:\n",
    "    low_zero_syn_net = build_classifier().cuda()\n",
    "    low_zero_syn_net.train()\n",
    "    train_classifier(low_zero_syn_net, get_optimizer(low_zero_syn_net), syn_low_zero_data_loader, key=\"Low Zero Synth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zer_syn:\n",
    "    device = torch.device(\"cuda\")\n",
    "    low_zero_syn_net.eval()\n",
    "    test(low_zero_syn_net, device, balanced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_classes = 10\n",
    "# model=low_zero_net\n",
    "\n",
    "# confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "# with torch.no_grad():\n",
    "#     for i, (inputs, classes) in enumerate(balanced_test):\n",
    "#         inputs = inputs.to(device)\n",
    "#         classes = classes.to(device)\n",
    "#         outputs = model(inputs)\n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "#         for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "#                 confusion_matrix[t.long(), p.long()] += 1\n",
    "# confusion_matrix = confusion_matrix.numpy()\n",
    "# np.fill_diagonal(confusion_matrix, 0)\n",
    "# vis.PlotHeatMap(confusion_matrix, \"Low Zero Confusionsdf\", False)\n",
    "#y is correct, x is predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(confusion_matrix[5][9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
