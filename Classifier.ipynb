{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from visdom import Visdom\n",
    "\n",
    "from lib.VisdomWrapper import *\n",
    "from lib.DataManager import *\n",
    "from lib.GANs import *\n",
    "from lib.DataCreationWrapper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Options\n",
    "bal_raw = False\n",
    "bal_syn = False\n",
    "bal_aug = False\n",
    "zer_raw = False\n",
    "zer_syn = False\n",
    "zer_aug = False\n",
    "nin_raw = True\n",
    "nin_syn = True\n",
    "nin_aug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "num_epochs = 30\n",
    "img_width = 28 #hardcoded\n",
    "n_features = img_width**2\n",
    "n_noise_features = 100\n",
    "n_classes = 10\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "vis = VisdomController()\n",
    "\n",
    "mnist = dset.MNIST('input', train=True, download=True, transform=T.ToTensor())\n",
    "\n",
    "mnist_test=dset.MNIST('input', train=False, download=True, transform=T.ToTensor())\n",
    "balanced_test = DataLoader(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_balance(labels):\n",
    "    cnts = torch.bincount(labels)\n",
    "    print(cnts)\n",
    "    max = torch.max(cnts)\n",
    "    print(max)\n",
    "    ret = (max * torch.ones(len(cnts)) - cnts).cpu().numpy().astype('int')\n",
    "    print(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frequency(data_loader, title):\n",
    "    x = np.arange(10)\n",
    "    cnts = torch.zeros(10)\n",
    "    for _, y in data_loader:\n",
    "        cnts += torch.bincount(y.cpu())\n",
    "    vis.CreateStaticBarPlot(cnts, x, title, \"Class\", \"Count\", \"FreqPlot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for OLD_GeneratorNetwork:\n\tMissing key(s) in state_dict: \"label_embedding.weight\", \"hidden0.1.weight\", \"hidden0.1.bias\", \"hidden0.1.running_mean\", \"hidden0.1.running_var\", \"hidden1.1.weight\", \"hidden1.1.bias\", \"hidden1.1.running_mean\", \"hidden1.1.running_var\", \"hidden2.0.weight\", \"hidden2.0.bias\", \"hidden2.1.weight\", \"hidden2.1.bias\", \"hidden2.1.running_mean\", \"hidden2.1.running_var\", \"out.0.weight\", \"out.0.bias\". \n\tUnexpected key(s) in state_dict: \"process_noise.0.weight\", \"process_noise.0.bias\", \"label_embedding.0.weight\", \"label_embedding.1.weight\", \"label_embedding.1.bias\", \"hidden0.2.weight\", \"hidden0.2.bias\", \"hidden0.2.running_mean\", \"hidden0.2.running_var\", \"hidden0.2.num_batches_tracked\". \n\tsize mismatch for hidden0.0.weight: copying a param with shape torch.Size([129, 64, 4, 4]) from checkpoint, the shape in current model is torch.Size([256, 110]).\n\tsize mismatch for hidden0.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for hidden1.0.weight: copying a param with shape torch.Size([64, 1, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 256]).\n\tsize mismatch for hidden1.0.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([512]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-81cce0116575>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnin_syn\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnin_aug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mnin_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOLD_GeneratorNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_noise_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mnin_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnin_nn_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mnin_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mnin_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cs682\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1052\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1053\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for OLD_GeneratorNetwork:\n\tMissing key(s) in state_dict: \"label_embedding.weight\", \"hidden0.1.weight\", \"hidden0.1.bias\", \"hidden0.1.running_mean\", \"hidden0.1.running_var\", \"hidden1.1.weight\", \"hidden1.1.bias\", \"hidden1.1.running_mean\", \"hidden1.1.running_var\", \"hidden2.0.weight\", \"hidden2.0.bias\", \"hidden2.1.weight\", \"hidden2.1.bias\", \"hidden2.1.running_mean\", \"hidden2.1.running_var\", \"out.0.weight\", \"out.0.bias\". \n\tUnexpected key(s) in state_dict: \"process_noise.0.weight\", \"process_noise.0.bias\", \"label_embedding.0.weight\", \"label_embedding.1.weight\", \"label_embedding.1.bias\", \"hidden0.2.weight\", \"hidden0.2.bias\", \"hidden0.2.running_mean\", \"hidden0.2.running_var\", \"hidden0.2.num_batches_tracked\". \n\tsize mismatch for hidden0.0.weight: copying a param with shape torch.Size([129, 64, 4, 4]) from checkpoint, the shape in current model is torch.Size([256, 110]).\n\tsize mismatch for hidden0.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for hidden1.0.weight: copying a param with shape torch.Size([64, 1, 4, 4]) from checkpoint, the shape in current model is torch.Size([512, 256]).\n\tsize mismatch for hidden1.0.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([512])."
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "bal_nn_file = \"models\\gen_nn_1_03-29-06\"\n",
    "zer_nn_file = \"models\\gen_nn_low_zero_BEST\"\n",
    "nin_nn_file = \"models\\gen_nn_high_nine_OLD\"\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    if bal_raw or bal_aug:\n",
    "        bal_train = DataLoader(mnist, batch_size =1000)\n",
    "        X, Y = data_loader_to_tensor(bal_train)\n",
    "        bal_train = DataLoader(TensorDataset(X, Y), batch_size=batch_size, shuffle=True)\n",
    "        X, Y = None, None\n",
    "        if bal_raw:\n",
    "            plot_frequency(bal_train, \"Balanced Raw Class Frequencies\")\n",
    "        \n",
    "        \n",
    "    if zer_raw or zer_aug:\n",
    "        zer_train = get_unbalanced_mnist([.01, .1, .1, .1, .1, .1, .1, .1, .1, .1], batch_size=1000)\n",
    "        X, Y = data_loader_to_tensor(zer_train)\n",
    "        zer_train = DataLoader(TensorDataset(X, Y), batch_size=batch_size, shuffle=True)\n",
    "        X, Y = None, None\n",
    "        if zer_raw:\n",
    "            plot_frequency(zer_train, \"Low Zero Raw Class Frequencies\")\n",
    "        \n",
    "    if nin_raw or nin_aug:\n",
    "        nin_train = get_unbalanced_mnist([.1, .1, .1, .1, .1, .1, .1, .1, .1, 1], batch_size=1000)\n",
    "        X, Y = data_loader_to_tensor(nin_train)\n",
    "        nin_train = DataLoader(TensorDataset(X, Y), batch_size=batch_size, shuffle=True)\n",
    "        X, Y = None, None\n",
    "        if nin_raw:\n",
    "            plot_frequency(nin_train, \"High Nine Raw Class Frequencies\")\n",
    "    \n",
    "    if bal_syn or bal_aug:\n",
    "        bal_gen = Conv_GeneratorNetwork(n_noise_features, n_features, n_classes)\n",
    "        bal_gen.load_state_dict(torch.load(bal_nn_file))\n",
    "        bal_gen = bal_gen.cuda()\n",
    "        bal_gen.eval()\n",
    "        if bal_syn:\n",
    "            synth_data, synth_labels = synthesize_data_of_each_label(bal_gen, gaussian_noise, 6000 * np.ones(10).astype('int'))\n",
    "            syn_bal_data_loader = DataLoader(TensorDataset(synth_data.view(len(synth_labels), 1, 28, 28), synth_labels), batch_size=batch_size, shuffle=True)\n",
    "            synth_data, synth_labels = None, None\n",
    "            plot_frequency(syn_bal_data_loader, \"Balanced Synthetic Class Frequencies\")\n",
    "\n",
    "        if bal_aug:\n",
    "            print(\"Augmenting bal\")\n",
    "            synth_data, synth_labels = synthesize_data_of_each_label(bal_gen, gaussian_noise, calc_balance(bal_train.dataset.tensors[1]))\n",
    "            synth_data = torch.cat((synth_data.view(len(synth_labels), 1, 28, 28).cuda(), bal_train.dataset.tensors[0].cuda()), dim=0)\n",
    "            synth_labels = torch.cat((synth_labels.cuda(), bal_train.dataset.tensors[1].cuda()))\n",
    "            aug_bal_data_loader = DataLoader(TensorDataset(synth_data.view(len(synth_labels), 1, 28, 28), synth_labels), batch_size=batch_size, shuffle=True)\n",
    "            synth_data, synth_labels = None, None\n",
    "            plot_frequency(aug_bal_data_loader, \"Balanced Augmented Class Frequencies\")\n",
    "\n",
    "    if zer_syn or zer_aug:\n",
    "        zer_gen = OLD_GeneratorNetwork(n_noise_features, n_features, n_classes)\n",
    "        zer_gen.load_state_dict(torch.load(zer_nn_file))\n",
    "        zer_gen.cuda()\n",
    "        zer_gen.eval()\n",
    "        if zer_syn:\n",
    "            synth_data, synth_labels = synthesize_data_of_each_label(zer_gen, gaussian_noise, 6000 * np.ones(10).astype('int'))\n",
    "            syn_low_zero_data_loader = DataLoader(TensorDataset(synth_data.view(len(synth_labels), 1, 28, 28), synth_labels), batch_size=batch_size, shuffle=True)\n",
    "            synth_data, synth_labels = None, None\n",
    "            plot_frequency(syn_low_zero_data_loader, \"Low Zero Synthetic Class Frequencies\")\n",
    "            \n",
    "        if zer_aug:\n",
    "            print(\"Augmenting zer\")\n",
    "            synth_data, synth_labels = synthesize_data_of_each_label(zer_gen, gaussian_noise, calc_balance(zer_train.dataset.tensors[1]))\n",
    "            synth_data = torch.cat((synth_data.view(len(synth_labels), 1, 28, 28).cuda(), zer_train.dataset.tensors[0].cuda()), dim=0)\n",
    "            synth_labels = torch.cat((synth_labels.cuda(), zer_train.dataset.tensors[1].cuda()))\n",
    "            aug_zer_data_loader = DataLoader(TensorDataset(synth_data.view(len(synth_labels), 1, 28, 28), synth_labels), batch_size=batch_size, shuffle=True)\n",
    "            synth_data, synth_labels = None, None\n",
    "            plot_frequency(aug_zer_data_loader, \"Low Zero Augmented Class Frequencies\")\n",
    "            \n",
    "\n",
    "    if nin_syn or nin_aug:\n",
    "        nin_gen = OLD_GeneratorNetwork(n_noise_features, n_features, n_classes)\n",
    "        nin_gen.load_state_dict(torch.load(nin_nn_file))\n",
    "        nin_gen.cuda()\n",
    "        nin_gen.eval()\n",
    "        if nin_syn:\n",
    "            synth_data, synth_labels = synthesize_data_of_each_label(nin_gen, gaussian_noise, 6000 * np.ones(10).astype('int'))\n",
    "            syn_nin_data_loader = DataLoader(TensorDataset(synth_data.view(len(synth_labels), 1, 28, 28), synth_labels), batch_size=batch_size, shuffle=True)\n",
    "            synth_data, synth_labels = None, None\n",
    "            plot_frequency(syn_nin_data_loader, \"High Nine Synthetic Class Frequencies\")\n",
    "            \n",
    "        if nin_aug:\n",
    "            print(\"Augmenting nin\")\n",
    "            synth_data, synth_labels = synthesize_data_of_each_label(nin_gen, gaussian_noise, calc_balance(nin_train.dataset.tensors[1]))\n",
    "            synth_data = torch.cat((synth_data.view(len(synth_labels), 1, 28, 28).cuda(), nin_train.dataset.tensors[0].cuda()), dim=0)\n",
    "            synth_labels = torch.cat((synth_labels.cuda(), nin_train.dataset.tensors[1].cuda()))\n",
    "            aug_nin_data_loader = DataLoader(TensorDataset(synth_data.view(len(synth_labels), 1, 28, 28), synth_labels), batch_size=batch_size, shuffle=True)\n",
    "            synth_data, synth_labels = None, None\n",
    "            plot_frequency(aug_nin_data_loader, \"High Nine Augmented Class Frequencies\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=5, stride=1),\n",
    "        nn.LeakyReLU(0.01),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=5, stride=1),\n",
    "        nn.LeakyReLU(0.01),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(4*4*64, 4*4*64, bias=True),\n",
    "        nn.LeakyReLU(0.01),\n",
    "        nn.Linear(4*4*64, 10, bias=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(classifier, optimizer, data, key=\"Loss\"):\n",
    "    for epoch in range(num_epochs):\n",
    "        for n_batch, (x, y) in enumerate(data):\n",
    "            if len(x) != batch_size:\n",
    "                continue\n",
    "            optimizer.zero_grad()\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            scores = classifier(x)\n",
    "            out = loss(scores, y)\n",
    "            out.backward()\n",
    "            optimizer.step()\n",
    "        display.clear_output(True)\n",
    "        print(\"Epoch {}, {} / {}\".format(epoch, n_batch, len(data)))\n",
    "        print(\"Loss: \", out.item())\n",
    "        vis.loss_axis = epoch\n",
    "        vis.PlotLoss(key, out.item())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    print('Accuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model, key):\n",
    "    nb_classes = 10\n",
    "\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, classes) in enumerate(balanced_test):\n",
    "            inputs = inputs.to(device)\n",
    "            classes = classes.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "    confusion_matrix = confusion_matrix.numpy()\n",
    "    np.fill_diagonal(confusion_matrix, 0)\n",
    "    vis.PlotHeatMap(confusion_matrix, key, False)\n",
    "#y is correct, x is predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bal_raw:\n",
    "    balanced_net = build_classifier().cuda()\n",
    "    balanced_net.train()\n",
    "    train_classifier(balanced_net, get_optimizer(balanced_net), bal_train, key=\"Balanced Raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bal_aug:\n",
    "    balanced_aug_net = build_classifier().cuda()\n",
    "    balanced_aug_net.train()\n",
    "    train_classifier(balanced_aug_net, get_optimizer(balanced_aug_net), aug_bal_data_loader, key=\"Balanced Aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bal_syn:\n",
    "    balanced_syn_net = build_classifier().cuda()\n",
    "    balanced_syn_net.train()\n",
    "    train_classifier(balanced_syn_net, get_optimizer(balanced_syn_net), syn_bal_data_loader, key=\"Balanced Synth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bal_raw:\n",
    "    device = torch.device(\"cuda\")\n",
    "    balanced_net.eval()\n",
    "    test(balanced_net, device, balanced_test)\n",
    "    plot_confusion_matrix(balanced_net, \"Balanced Raw\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bal_aug:\n",
    "    device = torch.device(\"cuda\")\n",
    "    balanced_aug_net.eval()\n",
    "    test(balanced_aug_net, device, balanced_test)\n",
    "    plot_confusion_matrix(balanced_aug_net, \"Balanced Augmented\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bal_syn:\n",
    "    device = torch.device(\"cuda\")\n",
    "    balanced_syn_net.eval()\n",
    "    test(balanced_syn_net, device, balanced_test)\n",
    "    plot_confusion_matrix(balanced_syn_net, \"Balanced Synthetic\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zer_raw:\n",
    "    low_zero_net = build_classifier().cuda()\n",
    "    low_zero_net.train()\n",
    "    train_classifier(low_zero_net, get_optimizer(low_zero_net), zer_train, key=\"Low Zero Raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if zer_syn:\n",
    "    low_zero_syn_net = build_classifier().cuda()\n",
    "    low_zero_syn_net.train()\n",
    "    train_classifier(low_zero_syn_net, get_optimizer(low_zero_syn_net), syn_low_zero_data_loader, key=\"Low Zero Synth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zer_aug:\n",
    "    low_zero_aug_net = build_classifier().cuda()\n",
    "    low_zero_aug_net.train()\n",
    "    train_classifier(low_zero_aug_net, get_optimizer(low_zero_aug_net), aug_zer_data_loader, key=\"Low Zero Aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zer_raw:\n",
    "    device = torch.device(\"cuda\")\n",
    "    low_zero_net.eval()\n",
    "    test(low_zero_net, device, balanced_test)\n",
    "    plot_confusion_matrix(low_zero_net, \"Low Zero Raw\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zer_syn:\n",
    "    device = torch.device(\"cuda\")\n",
    "    low_zero_syn_net.eval()\n",
    "    test(low_zero_syn_net, device, balanced_test)\n",
    "    plot_confusion_matrix(low_zero_syn_net, \"Low Zero Synthetic\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zer_aug:\n",
    "    device = torch.device(\"cuda\")\n",
    "    low_zero_aug_net.eval()\n",
    "    test(low_zero_aug_net, device, balanced_test)\n",
    "    plot_confusion_matrix(low_zero_aug_net, \"Low Zero Augmented\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nin_raw:\n",
    "    high_nine_net = build_classifier().cuda()\n",
    "    high_nine_net.train()\n",
    "    train_classifier(high_nine_net, get_optimizer(high_nine_net), nin_train, key=\"High Nine Raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if nin_syn:\n",
    "    nin_syn_net = build_classifier().cuda()\n",
    "    nin_syn_net.train()\n",
    "    train_classifier(nin_syn_net, get_optimizer(nin_syn_net), syn_nin_data_loader, key=\"High Nine Synth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nin_aug:\n",
    "    nin_aug_net = build_classifier().cuda()\n",
    "    nin_aug_net.train()\n",
    "    train_classifier(nin_aug_net, get_optimizer(nin_aug_net), aug_nin_data_loader, key=\"High Nine Aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nin_raw:\n",
    "    device = torch.device(\"cuda\")\n",
    "    high_nine_net.eval()\n",
    "    test(high_nine_net, device, balanced_test)\n",
    "    plot_confusion_matrix(high_nine_net, \"High Nine Raw\")                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nin_aug:\n",
    "    device = torch.device(\"cuda\")\n",
    "    nin_aug_net.eval()\n",
    "    test(nin_aug_net, device, balanced_test)\n",
    "    plot_confusion_matrix(nin_aug_net, \"High Nine Augmented\")                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nin_syn:\n",
    "    device = torch.device(\"cuda\")\n",
    "    nin_syn_net.eval()\n",
    "    test(nin_syn_net, device, balanced_test)\n",
    "    plot_confusion_matrix(nin_syn_net, \"High Nine Synthetic\")                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis.ShowImages(format_to_image(synthesize_data_from_each_label(zer_gen, gaussian_noise, n_classes).cpu().detach(), n_classes, img_width), \"Fortnite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
