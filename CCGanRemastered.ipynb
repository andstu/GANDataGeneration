{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from visdom import Visdom\n",
    "\n",
    "from lib.VisdomWrapper import *\n",
    "from lib.GANs import *\n",
    "from lib.DataCreationWrapper import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"input/creditcard.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "x = df.iloc[:, 1:-1].values\n",
    "y = df.iloc[:,-1:].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, random_state = 21, shuffle = True, stratify = y)\n",
    "\n",
    "# Store Num Features\n",
    "n_features = x.shape[1]\n",
    "n_noise_features = 10\n",
    "\n",
    "# Center Mean and Unit Variance\n",
    "scalar = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "x_train = scalar.fit_transform(x_train)\n",
    "x_test = scalar.fit_transform(x_test)\n",
    "\n",
    "# x_train = preprocessing.scale(x_train, axis = 0)\n",
    "# x_test = preprocessing.scale(x_test, axis = 0)\n",
    "\n",
    "# Mimic Real Data\n",
    "data_to_mimic = 0\n",
    "x_train = x_train[np.ravel(y_train == data_to_mimic)]\n",
    "y_train = y_train[y_train == data_to_mimic]\n",
    "\n",
    "# To Tensor\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_train = torch.from_numpy(y_train).double()\n",
    "y_test = torch.from_numpy(y_test).double()\n",
    "# if torch.cuda.is_available():\n",
    "#         x_train = x_train.cuda()\n",
    "#         x_test = x_test.cuda()\n",
    "#         y_train = y_train.cuda()\n",
    "#         y_test = y_test.cuda()\n",
    "\n",
    "# Creates Data Loader\n",
    "ds_train = data_utils.TensorDataset(x_train, y_train)\n",
    "data_loader = data_utils.DataLoader(ds_train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator_wass(discr_nn, discr_optimizer, loss, gen_nn, real_data, noise_function):\n",
    "    # Makes Fake Data    \n",
    "    batch_size = real_data.size(0)\n",
    "    fake_data = synthesize_data(gen_nn, batch_size, noise_function)\n",
    "\n",
    "    # Zero Grad\n",
    "    discr_optimizer.zero_grad()\n",
    "    \n",
    "    # Prediction on Fake Data\n",
    "    prediction_fake = discr_nn(fake_data)\n",
    "    \n",
    "    # Prediction on Real Data\n",
    "    prediction_real = discr_nn(real_data)\n",
    "    \n",
    "    loss = - torch.mean(prediction_real) + torch.mean(prediction_fake)\n",
    "    loss.backward()\n",
    "    \n",
    "    discr_optimizer.step()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def train_generator_wass(gen_nn, gen_optimizer, loss, discr_nn, real_data, noise_function):\n",
    "    # Makes Fake Data\n",
    "    batch_size = real_data.size(0)\n",
    "    fake_data = synthesize_data(gen_nn, batch_size, noise_function)\n",
    "\n",
    "    # Zero Grad\n",
    "    gen_optimizer.zero_grad()\n",
    "        \n",
    "    # Prediction on Fake Data\n",
    "    prediction_fake = discr_nn(fake_data)\n",
    "    \n",
    "    loss = - torch.mean(prediction_fake)\n",
    "    loss.backward()\n",
    "    \n",
    "    gen_optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "\n",
    "# Models\n",
    "discr_nn = DiscriminatorNetwork(n_features)\n",
    "gen_nn = GeneratorNetwork(n_noise_features, n_features)\n",
    "if torch.cuda.is_available():\n",
    "    discr_nn.cuda()\n",
    "    gen_nn.cuda()\n",
    "\n",
    "# Optimizers\n",
    "discr_optimizer = optim.SGD(discr_nn.parameters(), lr=1e-2)\n",
    "gen_optimizer = optim.Adam(gen_nn.parameters(), lr=1e-3)\n",
    "\n",
    "# Loss\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "# Visualizer\n",
    "vis = VisdomController()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 2200 / 2275\n",
      "discr_loss :  tensor(-0.0235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "gen_loss :  tensor(-0.2906, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Time Elapsed :  0.04900002479553223\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "num_epochs = 25\n",
    "noise_function = gaussian_noise\n",
    "num_scatter_points = 80\n",
    "\n",
    "# One Off Graphs\n",
    "vis.ClearPlots()\n",
    "vis.PlotRealFeatureDistributionComparison(5, 6, x_train, num_scatter_points)\n",
    "\n",
    "loss_axis = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch, (batch, _) in enumerate(data_loader):\n",
    "        real_batch = Variable(batch)\n",
    "        if torch.cuda.is_available():\n",
    "            real_batch = real_batch.cuda()\n",
    "        \n",
    "        t_start = millis = time.time()\n",
    "        batch_size = real_batch.size(0)\n",
    "        \n",
    "        discr_loss = train_discriminator_wass(discr_nn, discr_optimizer, loss, gen_nn, real_batch, noise_function)\n",
    "        gen_loss = train_generator_wass(gen_nn, gen_optimizer, loss, discr_nn, real_batch, noise_function)\n",
    "        \n",
    "        if (n_batch % 100 == 0):\n",
    "            display.clear_output(True)\n",
    "            \n",
    "            # Basic Data            \n",
    "            print(\"Epoch {}, {} / {}\".format(epoch, n_batch, len(data_loader)))\n",
    "            print(\"discr_loss : \", discr_loss)\n",
    "            print(\"gen_loss : \", gen_loss) \n",
    "            \n",
    "            vis.PlotLoss(\"Discr Loss\", loss_axis, discr_loss.item())\n",
    "            vis.PlotLoss(\"Gen Loss\", loss_axis, gen_loss.item())\n",
    "            loss_axis += 1\n",
    "            \n",
    "            t_end = millis = time.time()\n",
    "            print(\"Time Elapsed : \", t_end - t_start)\n",
    "          \n",
    "    vis.PlotFakeFeatureDistributionComparison(5, 6, gen_nn, num_scatter_points, noise_function)\n",
    "\n",
    "torch.save(gen_nn.state_dict(),\"models\\gen_nn\" + str(data_to_mimic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
